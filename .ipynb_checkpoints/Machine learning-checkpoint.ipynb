{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7b5d81",
   "metadata": {},
   "source": [
    "# Importing the necessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f415884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt \n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab787f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc = pd.read_csv('cleaned_chocolate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913e346",
   "metadata": {},
   "source": [
    "# One-hot encoding for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "choc_ohe = choc[['country_of_bean_origin',\n",
    "                 'first_taste', 'second_taste', 'third_taste', 'fourth_taste']]\n",
    "choc_ohe = pd.get_dummies(data = choc_ohe)\n",
    "\n",
    "# extracting rest of the predictors\n",
    "choc_num = choc[['cocoa_percent', 'counts_of_ingredients', 'number_of_taste']]\n",
    "                 #'cocoa_butter', 'vanilla', 'lecithin', 'salt', 'sugar', 'sweetener_without_sugar']]\n",
    "\n",
    "# extracting response\n",
    "choc_response = choc['rating_category']\n",
    "\n",
    "# combining predictors and response\n",
    "choc_ohe = pd.concat([choc_ohe, choc_response, choc_num], sort = False, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118ed2c",
   "metadata": {},
   "source": [
    "For our models, we are going to use Stratified K Fold cross validation to evaluate the model, as well as calculating its accuracy rate on a training and testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8556a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c725a",
   "metadata": {},
   "source": [
    "# Classification tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05014f1",
   "metadata": {},
   "source": [
    "We start off with a very simple model, a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9db588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y1 = pd.DataFrame(choc_ohe['rating_category'])\n",
    "X1 = pd.DataFrame(choc_ohe.drop('rating_category', axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174ce00",
   "metadata": {},
   "source": [
    "Using stratified K fold cross validation to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679eef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree = DecisionTreeClassifier(max_depth = 40)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(dectree, X1, y1, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c8a1f",
   "metadata": {},
   "source": [
    "Test the model on a train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2)\n",
    "dectree.fit(X1_train, y1_train)                     # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y1_train_pred = dectree.predict(X1_train)\n",
    "y1_test_pred = dectree.predict(X1_test)\n",
    "\n",
    "# Check the Goodness of Fit on Train Data\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X1_train, y1_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit on Test Data\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X1_test, y1_test))\n",
    "print()\n",
    "\n",
    "trainData = confusion_matrix(y1_train, y1_train_pred)\n",
    "testData = confusion_matrix(y1_test, y1_test_pred)\n",
    "\n",
    "print(\"True '2' rate Train :\\t\", (trainData[2][2]/(trainData[2][0]+trainData[2][1]+trainData[2][2])))\n",
    "print(\"True '1' rate Train :\\t\", (trainData[1][1]/(trainData[1][0]+trainData[1][1]+trainData[1][2])))\n",
    "print(\"True '0' rate Train :\\t\", (trainData[0][0]/(trainData[0][0]+trainData[0][1]+trainData[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Train :\\t\", ((trainData[1][2]+trainData[0][2])/((trainData[1][2]+trainData[0][2]+trainData[1][1]+trainData[0][1]+trainData[1][0]+trainData[0][0]))))\n",
    "print(\"False '1' rate Train :\\t\", ((trainData[2][1]+trainData[0][1])/((trainData[2][1]+trainData[0][1]+trainData[2][2]+trainData[0][2]+trainData[2][0]+trainData[0][0]))))\n",
    "print(\"False '0' rate Train :\\t\", ((trainData[1][0]+trainData[2][0])/((trainData[1][0]+trainData[2][0]+trainData[1][1]+trainData[2][1]+trainData[1][2]+trainData[2][2]))))\n",
    "print()\n",
    "\n",
    "print(\"True '2' rate Test :\\t\", (testData[2][2]/(testData[2][0]+testData[2][1]+testData[2][2])))\n",
    "print(\"True '1' rate Test :\\t\", (testData[1][1]/(testData[1][0]+testData[1][1]+testData[1][2])))\n",
    "print(\"True '0' rate Test :\\t\", (testData[0][0]/(testData[0][0]+testData[0][1]+testData[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Test :\\t\", ((testData[1][2]+testData[0][2])/((testData[1][2]+testData[0][2]+testData[1][1]+testData[0][1]+testData[1][0]+testData[0][0]))))\n",
    "print(\"False '1' rate Test :\\t\", ((testData[2][1]+testData[0][1])/((testData[2][1]+testData[0][1]+testData[2][2]+testData[0][2]+testData[2][0]+testData[0][0]))))\n",
    "print(\"False '0' rate Test :\\t\", ((testData[1][0]+testData[2][0])/((testData[1][0]+testData[2][0]+testData[1][1]+testData[2][1]+testData[1][2]+testData[2][2]))))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(2, 1, figsize=(8, 16))\n",
    "sb.heatmap(trainData,\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(testData, \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f9a46",
   "metadata": {},
   "source": [
    "Overall, the Classification Tree model did quite a bad job of predicting our chocolate rating, let's see how we can improve upon that accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ac4a7",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19abb37",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74bfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(choc_ohe['rating_category'])\n",
    "X = pd.DataFrame(choc_ohe.drop('rating_category', axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16a7e5",
   "metadata": {},
   "source": [
    "Using stratified K fold cross validation to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier(n_estimators = 400, max_depth = 60)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(rforest, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19d284",
   "metadata": {},
   "source": [
    "Test the model on a train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f23220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Fit Random Forest on Train Data\n",
    "rforest.fit(X_train, y_train.rating_category.ravel())\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = rforest.predict(X_train)\n",
    "y_test_pred = rforest.predict(X_test)\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"True '2' rate Train :\\t\", (cmTrain[2][2]/(cmTrain[2][0]+cmTrain[2][1]+cmTrain[2][2])))\n",
    "print(\"True '1' rate Train :\\t\", (cmTrain[1][1]/(cmTrain[1][0]+cmTrain[1][1]+cmTrain[1][2])))\n",
    "print(\"True '0' rate Train :\\t\", (cmTrain[0][0]/(cmTrain[0][0]+cmTrain[0][1]+cmTrain[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Train :\\t\", ((cmTrain[1][2]+cmTrain[0][2])/((cmTrain[1][2]+cmTrain[0][2]+cmTrain[1][1]+cmTrain[0][1]+cmTrain[1][0]+cmTrain[0][0]))))\n",
    "print(\"False '1' rate Train :\\t\", ((cmTrain[2][1]+cmTrain[0][1])/((cmTrain[2][1]+cmTrain[0][1]+cmTrain[2][2]+cmTrain[0][2]+cmTrain[2][0]+cmTrain[0][0]))))\n",
    "print(\"False '0' rate Train :\\t\", ((cmTrain[1][0]+cmTrain[2][0])/((cmTrain[1][0]+cmTrain[2][0]+cmTrain[1][1]+cmTrain[2][1]+cmTrain[1][2]+cmTrain[2][2]))))\n",
    "print()\n",
    "\n",
    "print(\"True '2' rate Test :\\t\", (cmTest[2][2]/(cmTest[2][0]+cmTest[2][1]+cmTest[2][2])))\n",
    "print(\"True '1' rate Test :\\t\", (cmTest[1][1]/(cmTest[1][0]+cmTest[1][1]+cmTest[1][2])))\n",
    "print(\"True '0' rate Test :\\t\", (cmTest[0][0]/(cmTest[0][0]+cmTest[0][1]+cmTest[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Test :\\t\", ((cmTest[1][2]+cmTest[0][2])/((cmTest[1][2]+cmTest[0][2]+cmTest[1][1]+cmTest[0][1]+cmTest[1][0]+cmTest[0][0]))))\n",
    "print(\"False '1' rate Test :\\t\", ((cmTest[2][1]+cmTest[0][1])/((cmTest[2][1]+cmTest[0][1]+cmTest[2][2]+cmTest[0][2]+cmTest[2][0]+cmTest[0][0]))))\n",
    "print(\"False '0' rate Test :\\t\", ((cmTest[1][0]+cmTest[2][0])/((cmTest[1][0]+cmTest[2][0]+cmTest[1][1]+cmTest[2][1]+cmTest[1][2]+cmTest[2][2]))))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "f, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "sb.heatmap(cmTrain, annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(cmTest, annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d709a34",
   "metadata": {},
   "source": [
    "We have good accuracy on the training data set, but horrible accuracy on the test dataset, this might be a case of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7598e5d",
   "metadata": {},
   "source": [
    "# Upsampling the minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which category of rating is imbalanced\n",
    "choc_ohe.rating_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6eb614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample rating_category\n",
    "from sklearn.utils import resample\n",
    "\n",
    "rating0 = choc_ohe[choc_ohe.rating_category == '0']\n",
    "rating1 = choc_ohe[choc_ohe.rating_category == '1']\n",
    "rating2 = choc_ohe[choc_ohe.rating_category == '2']\n",
    " \n",
    "# Upsampling 0 and 1\n",
    "rating0_up = resample(rating0,\n",
    "                      replace=True,                  # sample with replacement\n",
    "                      n_samples=rating2.shape[0])    # to match number '2'\n",
    "\n",
    "rating1_up = resample(rating1,\n",
    "                      replace=True,                  # sample with replacement\n",
    "                      n_samples=rating2.shape[0])    # to match number '2'\n",
    " \n",
    "# Combine the three classes back after upsampling\n",
    "choc_ohe_up = pd.concat([rating2, rating0_up, rating1_up])\n",
    " \n",
    "# Check the ratio of the classes\n",
    "choc_ohe_up['rating_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c73b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(choc_ohe_up['rating_category'])\n",
    "X = pd.DataFrame(choc_ohe_up.drop('rating_category', axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe54f19",
   "metadata": {},
   "source": [
    "Using stratified K fold cross validation to evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier(n_estimators = 1000, max_depth = 80)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(rforest, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7ee9a",
   "metadata": {},
   "source": [
    "Test the model on a train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca02d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Fit Random Forest on Train Data\n",
    "rforest.fit(X_train, y_train.rating_category.ravel())\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_train, y_train))\n",
    "print()\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = rforest.predict(X_train)\n",
    "y_test_pred = rforest.predict(X_test)\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"True '2' rate Train :\\t\", (cmTrain[2][2]/(cmTrain[2][0]+cmTrain[2][1]+cmTrain[2][2])))\n",
    "print(\"True '1' rate Train :\\t\", (cmTrain[1][1]/(cmTrain[1][0]+cmTrain[1][1]+cmTrain[1][2])))\n",
    "print(\"True '0' rate Train :\\t\", (cmTrain[0][0]/(cmTrain[0][0]+cmTrain[0][1]+cmTrain[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Train :\\t\", ((cmTrain[1][2]+cmTrain[0][2])/((cmTrain[1][2]+cmTrain[0][2]+cmTrain[1][1]+cmTrain[0][1]+cmTrain[1][0]+cmTrain[0][0]))))\n",
    "print(\"False '1' rate Train :\\t\", ((cmTrain[2][1]+cmTrain[0][1])/((cmTrain[2][1]+cmTrain[0][1]+cmTrain[2][2]+cmTrain[0][2]+cmTrain[2][0]+cmTrain[0][0]))))\n",
    "print(\"False '0' rate Train :\\t\", ((cmTrain[1][0]+cmTrain[2][0])/((cmTrain[1][0]+cmTrain[2][0]+cmTrain[1][1]+cmTrain[2][1]+cmTrain[1][2]+cmTrain[2][2]))))\n",
    "print()\n",
    "\n",
    "print(\"True '2' rate Test :\\t\", (cmTest[2][2]/(cmTest[2][0]+cmTest[2][1]+cmTest[2][2])))\n",
    "print(\"True '1' rate Test :\\t\", (cmTest[1][1]/(cmTest[1][0]+cmTest[1][1]+cmTest[1][2])))\n",
    "print(\"True '0' rate Test :\\t\", (cmTest[0][0]/(cmTest[0][0]+cmTest[0][1]+cmTest[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Test :\\t\", ((cmTest[1][2]+cmTest[0][2])/((cmTest[1][2]+cmTest[0][2]+cmTest[1][1]+cmTest[0][1]+cmTest[1][0]+cmTest[0][0]))))\n",
    "print(\"False '1' rate Test :\\t\", ((cmTest[2][1]+cmTest[0][1])/((cmTest[2][1]+cmTest[0][1]+cmTest[2][2]+cmTest[0][2]+cmTest[2][0]+cmTest[0][0]))))\n",
    "print(\"False '0' rate Test :\\t\", ((cmTest[1][0]+cmTest[2][0])/((cmTest[1][0]+cmTest[2][0]+cmTest[1][1]+cmTest[2][1]+cmTest[1][2]+cmTest[2][2]))))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "f, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "sb.heatmap(cmTrain, annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(cmTest, annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254341e6",
   "metadata": {},
   "source": [
    "Much better accuracy, and less bias towards the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056cdd0c",
   "metadata": {},
   "source": [
    "# Removing minority classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df819b1",
   "metadata": {},
   "source": [
    "In the columns \"country_of_bean_origin\", there are a lot of data which only appeared 2 or 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_xoutlier = choc[choc[\"country_of_bean_origin\"].isin(beanOriginTop[\"index\"])]\n",
    "choc_xoutlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d72f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "choc_xoutlier_ohe = choc_xoutlier[['country_of_bean_origin',\n",
    "                                   'first_taste', 'second_taste', 'third_taste', 'fourth_taste']]\n",
    "choc_xoutlier_ohe = pd.get_dummies(data = choc_xoutlier_ohe)\n",
    "\n",
    "# extracting rest of the predictors\n",
    "choc_xoutlier_num = choc_xoutlier[['cocoa_percent', 'counts_of_ingredients', 'number_of_taste']]\n",
    "                                   #'cocoa_butter', 'vanilla', 'lecithin', 'salt', 'sugar', 'sweetener_without_sugar']]\n",
    "\n",
    "# extracting response\n",
    "choc_xoutlier_response = choc_xoutlier['rating_category']\n",
    "\n",
    "#combining predictors and response\n",
    "choc_xoutlier_ohe = pd.concat([choc_xoutlier_ohe, choc_xoutlier_response, choc_xoutlier_num], sort = False, axis = 1)\n",
    "choc_xoutlier_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_xoutlier_ohe.rating_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample rating_category\n",
    "rating0 = choc_xoutlier_ohe[choc_xoutlier_ohe.rating_category == '0']\n",
    "rating1 = choc_xoutlier_ohe[choc_xoutlier_ohe.rating_category == '1']\n",
    "rating2 = choc_xoutlier_ohe[choc_xoutlier_ohe.rating_category == '2']\n",
    " \n",
    "# Upsampling 0 and 1\n",
    "rating0_up = resample(rating0,\n",
    "                      replace=True,                  # sample with replacement\n",
    "                      n_samples=rating2.shape[0])    # to match number '2'\n",
    "\n",
    "rating1_up = resample(rating1,\n",
    "                      replace=True,                  # sample with replacement\n",
    "                      n_samples=rating2.shape[0])    # to match number '2'\n",
    " \n",
    "# Combine the three classes back after upsampling\n",
    "choc_xoutlier_ohe_up = pd.concat([rating2, rating0_up, rating1_up])\n",
    " \n",
    "# Check the ratio of the classes\n",
    "choc_xoutlier_ohe_up['rating_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79950a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(choc_xoutlier_ohe_up['rating_category'])\n",
    "X = pd.DataFrame(choc_xoutlier_ohe_up.drop('rating_category', axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f6aec",
   "metadata": {},
   "source": [
    "Using stratified K fold cross validation to evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cceb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier(n_estimators = 800, max_depth = 80)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(rforest, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc86666",
   "metadata": {},
   "source": [
    "Test the model on a train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415493df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Fit Random Forest on Train Data\n",
    "rforest.fit(X_train, y_train.rating_category.ravel())\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_train, y_train))\n",
    "print()\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = rforest.predict(X_train)\n",
    "y_test_pred = rforest.predict(X_test)\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"True '2' rate Train :\\t\", (cmTrain[2][2]/(cmTrain[2][0]+cmTrain[2][1]+cmTrain[2][2])))\n",
    "print(\"True '1' rate Train :\\t\", (cmTrain[1][1]/(cmTrain[1][0]+cmTrain[1][1]+cmTrain[1][2])))\n",
    "print(\"True '0' rate Train :\\t\", (cmTrain[0][0]/(cmTrain[0][0]+cmTrain[0][1]+cmTrain[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Train :\\t\", ((cmTrain[1][2]+cmTrain[0][2])/((cmTrain[1][2]+cmTrain[0][2]+cmTrain[1][1]+cmTrain[0][1]+cmTrain[1][0]+cmTrain[0][0]))))\n",
    "print(\"False '1' rate Train :\\t\", ((cmTrain[2][1]+cmTrain[0][1])/((cmTrain[2][1]+cmTrain[0][1]+cmTrain[2][2]+cmTrain[0][2]+cmTrain[2][0]+cmTrain[0][0]))))\n",
    "print(\"False '0' rate Train :\\t\", ((cmTrain[1][0]+cmTrain[2][0])/((cmTrain[1][0]+cmTrain[2][0]+cmTrain[1][1]+cmTrain[2][1]+cmTrain[1][2]+cmTrain[2][2]))))\n",
    "print()\n",
    "\n",
    "print(\"True '2' rate Test :\\t\", (cmTest[2][2]/(cmTest[2][0]+cmTest[2][1]+cmTest[2][2])))\n",
    "print(\"True '1' rate Test :\\t\", (cmTest[1][1]/(cmTest[1][0]+cmTest[1][1]+cmTest[1][2])))\n",
    "print(\"True '0' rate Test :\\t\", (cmTest[0][0]/(cmTest[0][0]+cmTest[0][1]+cmTest[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Test :\\t\", ((cmTest[1][2]+cmTest[0][2])/((cmTest[1][2]+cmTest[0][2]+cmTest[1][1]+cmTest[0][1]+cmTest[1][0]+cmTest[0][0]))))\n",
    "print(\"False '1' rate Test :\\t\", ((cmTest[2][1]+cmTest[0][1])/((cmTest[2][1]+cmTest[0][1]+cmTest[2][2]+cmTest[0][2]+cmTest[2][0]+cmTest[0][0]))))\n",
    "print(\"False '0' rate Test :\\t\", ((cmTest[1][0]+cmTest[2][0])/((cmTest[1][0]+cmTest[2][0]+cmTest[1][1]+cmTest[2][1]+cmTest[1][2]+cmTest[2][2]))))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "f, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "sb.heatmap(cmTrain, annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(cmTest, annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185a157",
   "metadata": {},
   "source": [
    "To add comment here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8392c",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa35e1c1",
   "metadata": {},
   "source": [
    "Let's try a more sophisticated model, Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbcaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# gradient boosting for classification in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(choc_xoutlier_ohe_up['rating_category'])\n",
    "X = pd.DataFrame(choc_xoutlier_ohe_up.drop('rating_category', axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d72d8",
   "metadata": {},
   "source": [
    "Using stratified K fold cross validation to evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GradBoost = GradientBoostingClassifier(loss = \"deviance\", learning_rate = 0.1, n_estimators = 500, subsample = 0.5, max_depth = 6) \n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(GradBoost, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86894ea",
   "metadata": {},
   "source": [
    "Test the model on a train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568282c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GradBoost.fit(X_train, y_train)\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", GradBoost.score(X_train, y_train))\n",
    "print()\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", GradBoost.score(X_test, y_test))\n",
    "print()\n",
    "y_train_pred = GradBoost.predict(X_train)\n",
    "y_test_pred = GradBoost.predict(X_test)\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"True '2' rate Train :\\t\", (cmTrain[2][2]/(cmTrain[2][0]+cmTrain[2][1]+cmTrain[2][2])))\n",
    "print(\"True '1' rate Train :\\t\", (cmTrain[1][1]/(cmTrain[1][0]+cmTrain[1][1]+cmTrain[1][2])))\n",
    "print(\"True '0' rate Train :\\t\", (cmTrain[0][0]/(cmTrain[0][0]+cmTrain[0][1]+cmTrain[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Train :\\t\", ((cmTrain[1][2]+cmTrain[0][2])/((cmTrain[1][2]+cmTrain[0][2]+cmTrain[1][1]+cmTrain[0][1]+cmTrain[1][0]+cmTrain[0][0]))))\n",
    "print(\"False '1' rate Train :\\t\", ((cmTrain[2][1]+cmTrain[0][1])/((cmTrain[2][1]+cmTrain[0][1]+cmTrain[2][2]+cmTrain[0][2]+cmTrain[2][0]+cmTrain[0][0]))))\n",
    "print(\"False '0' rate Train :\\t\", ((cmTrain[1][0]+cmTrain[2][0])/((cmTrain[1][0]+cmTrain[2][0]+cmTrain[1][1]+cmTrain[2][1]+cmTrain[1][2]+cmTrain[2][2]))))\n",
    "print()\n",
    "\n",
    "print(\"True '2' rate Test :\\t\", (cmTest[2][2]/(cmTest[2][0]+cmTest[2][1]+cmTest[2][2])))\n",
    "print(\"True '1' rate Test :\\t\", (cmTest[1][1]/(cmTest[1][0]+cmTest[1][1]+cmTest[1][2])))\n",
    "print(\"True '0' rate Test :\\t\", (cmTest[0][0]/(cmTest[0][0]+cmTest[0][1]+cmTest[0][2])))\n",
    "print()\n",
    "\n",
    "print(\"False '2' rate Test :\\t\", ((cmTest[1][2]+cmTest[0][2])/((cmTest[1][2]+cmTest[0][2]+cmTest[1][1]+cmTest[0][1]+cmTest[1][0]+cmTest[0][0]))))\n",
    "print(\"False '1' rate Test :\\t\", ((cmTest[2][1]+cmTest[0][1])/((cmTest[2][1]+cmTest[0][1]+cmTest[2][2]+cmTest[0][2]+cmTest[2][0]+cmTest[0][0]))))\n",
    "print(\"False '0' rate Test :\\t\", ((cmTest[1][0]+cmTest[2][0])/((cmTest[1][0]+cmTest[2][0]+cmTest[1][1]+cmTest[2][1]+cmTest[1][2]+cmTest[2][2]))))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "f, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "sb.heatmap(cmTrain, annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(cmTest, annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
